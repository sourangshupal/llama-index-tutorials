{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 5: Hybrid Search & Reranking\n",
    "\n",
    "**Difficulty:** Advanced | **Estimated Time:** 150-180 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. ‚úÖ Understand dense vs sparse vectors and BM25 algorithm\n",
    "2. ‚úÖ Implement hybrid search combining semantic and keyword matching\n",
    "3. ‚úÖ Configure alpha parameter for optimal score fusion\n",
    "4. ‚úÖ Apply reranking models (Cohere, SentenceTransformer cross-encoders)\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Notebooks 1-4\n",
    "- Understanding of embeddings and retrieval\n",
    "- Optional: Cohere API key for reranking (free tier available)\n",
    "\n",
    "## Curriculum Coverage\n",
    "\n",
    "- **Section 4.1:** Hybrid Search Fundamentals\n",
    "- **Section 4.2:** Implementing Hybrid Search\n",
    "- **Section 4.5:** Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core LlamaIndex\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Settings,\n",
    "    Document,\n",
    "    StorageContext,\n",
    ")\n",
    "from llama_index.core.query_engine import BaseQueryEngine\n",
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import QueryBundle, NodeWithScore\n",
    "\n",
    "# Reranking\n",
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "try:\n",
    "    from llama_index.postprocessor.cohere_rerank import CohereRerank\n",
    "    COHERE_AVAILABLE = True\n",
    "except ImportError:\n",
    "    COHERE_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Cohere rerank not available. Install with: pip install llama-index-postprocessor-cohere-rerank\")\n",
    "\n",
    "# Vector Stores (for hybrid search)\n",
    "try:\n",
    "    from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "    from qdrant_client import QdrantClient\n",
    "    QDRANT_AVAILABLE = True\n",
    "except ImportError:\n",
    "    QDRANT_AVAILABLE = False\n",
    "    print(\"‚ö†Ô∏è  Qdrant not available. Install with: pip install llama-index-vector-stores-qdrant qdrant-client\")\n",
    "\n",
    "# LLM and Embeddings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Utilities\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import time\n",
    "from typing import List, Optional, Any\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"‚úÖ Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Settings configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Settings\n",
    "load_dotenv()\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Settings configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Understanding Hybrid Search\n",
    "\n",
    "### Dense vs Sparse Vectors\n",
    "\n",
    "**Dense Vectors (Semantic):**\n",
    "- Generated by neural embedding models\n",
    "- All dimensions have non-zero values\n",
    "- Capture semantic meaning\n",
    "- Example: `[0.12, -0.34, 0.56, ..., 0.89]` (1536 dims)\n",
    "\n",
    "**Sparse Vectors (Keyword/BM25):**\n",
    "- Based on term frequency (TF-IDF, BM25)\n",
    "- Most dimensions are zero\n",
    "- Capture exact term matches\n",
    "- Example: `{\"vector\": 0.8, \"search\": 0.6, \"database\": 0.4}`\n",
    "\n",
    "### Why Hybrid?\n",
    "\n",
    "**Strengths of Each:**\n",
    "\n",
    "| Aspect | Dense (Semantic) | Sparse (Keyword) |\n",
    "|--------|-----------------|------------------|\n",
    "| **Synonyms** | ‚úÖ Excellent | ‚ùå Poor |\n",
    "| **Exact terms** | ‚ö†Ô∏è  Good | ‚úÖ Excellent |\n",
    "| **Context** | ‚úÖ Excellent | ‚ùå None |\n",
    "| **Rare terms** | ‚ö†Ô∏è  Good | ‚úÖ Excellent |\n",
    "| **Speed** | Fast | Very Fast |\n",
    "\n",
    "**Hybrid combines both for best results!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BM25 Algorithm Overview\n",
    "\n",
    "**BM25 (Best Matching 25)** is a ranking function:\n",
    "\n",
    "```\n",
    "BM25(D, Q) = Œ£ IDF(qi) * (f(qi, D) * (k1 + 1)) / (f(qi, D) + k1 * (1 - b + b * |D| / avgdl))\n",
    "```\n",
    "\n",
    "Where:\n",
    "- `D`: Document\n",
    "- `Q`: Query\n",
    "- `f(qi, D)`: Term frequency of query term qi in document D\n",
    "- `|D|`: Length of document D\n",
    "- `avgdl`: Average document length\n",
    "- `k1`: Term frequency saturation (typically 1.2-2.0)\n",
    "- `b`: Length normalization (typically 0.75)\n",
    "- `IDF(qi)`: Inverse document frequency\n",
    "\n",
    "**Key Properties:**\n",
    "- **Diminishing returns**: Additional term occurrences matter less\n",
    "- **Length normalization**: Longer documents aren't unfairly penalized\n",
    "- **IDF weighting**: Rare terms score higher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Prepare Sample Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Created 6 documents for hybrid search\n",
      "  - vector_databases (overview)\n",
      "  - bm25 (technical)\n",
      "  - hybrid_search (technical)\n",
      "  - reranking (technical)\n",
      "  - qdrant (product)\n",
      "  - alpha_tuning (guide)\n"
     ]
    }
   ],
   "source": [
    "# Create comprehensive documents for hybrid search testing\n",
    "documents = [\n",
    "    Document(\n",
    "        text=\"\"\"Vector databases are specialized systems for storing and querying high-dimensional vectors. \n",
    "        Popular vector databases include Qdrant, Pinecone, Weaviate, and Milvus. They use algorithms like \n",
    "        HNSW (Hierarchical Navigable Small World) for approximate nearest neighbor search. Vector databases \n",
    "        are essential for semantic search, recommendation systems, and RAG applications.\"\"\",\n",
    "        metadata={\"topic\": \"vector_databases\", \"doc_type\": \"overview\", \"keywords\": \"vector database HNSW\"}\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"\"\"BM25 is a probabilistic ranking function used for information retrieval. It improves upon \n",
    "        TF-IDF by adding term frequency saturation and document length normalization. The formula includes \n",
    "        parameters k1 (controls term frequency saturation) and b (controls length normalization). BM25 is \n",
    "        widely used in search engines like Elasticsearch and provides excellent keyword-based retrieval.\"\"\",\n",
    "        metadata={\"topic\": \"bm25\", \"doc_type\": \"technical\", \"keywords\": \"BM25 ranking TF-IDF\"}\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"\"\"Hybrid search combines semantic vector search with keyword-based methods like BM25. This \n",
    "        approach leverages the strengths of both: semantic search handles synonyms and context, while \n",
    "        keyword search ensures exact term matches. The results are typically fused using reciprocal rank \n",
    "        fusion or weighted score combination with an alpha parameter.\"\"\",\n",
    "        metadata={\"topic\": \"hybrid_search\", \"doc_type\": \"technical\", \"keywords\": \"hybrid search semantic keyword\"}\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"\"\"Reranking is a two-stage retrieval process where an initial set of candidates is retrieved \n",
    "        cheaply, then reranked using a more expensive but accurate model. Cross-encoder models like those \n",
    "        from sentence-transformers are popular for reranking. Cohere provides a reranking API that achieves \n",
    "        excellent results. Reranking significantly improves retrieval quality at modest cost increase.\"\"\",\n",
    "        metadata={\"topic\": \"reranking\", \"doc_type\": \"technical\", \"keywords\": \"reranking cross-encoder Cohere\"}\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"\"\"Qdrant is a vector database written in Rust that supports both dense and sparse vectors. \n",
    "        It enables hybrid search by combining semantic similarity with BM25 keyword matching. Qdrant uses \n",
    "        HNSW indexing for fast approximate nearest neighbor search and supports filtering, quantization, \n",
    "        and distributed deployments. It's particularly well-suited for production RAG systems.\"\"\",\n",
    "        metadata={\"topic\": \"qdrant\", \"doc_type\": \"product\", \"keywords\": \"Qdrant vector database hybrid\"}\n",
    "    ),\n",
    "    Document(\n",
    "        text=\"\"\"The alpha parameter in hybrid search controls the balance between semantic and keyword scores. \n",
    "        Alpha=0 means pure keyword (BM25) search. Alpha=1 means pure semantic search. Alpha=0.5 gives equal \n",
    "        weight to both. The optimal alpha depends on your data and queries - typically between 0.3-0.7. \n",
    "        You should tune alpha on a validation set for best results.\"\"\",\n",
    "        metadata={\"topic\": \"alpha_tuning\", \"doc_type\": \"guide\", \"keywords\": \"alpha parameter hybrid tuning\"}\n",
    "    ),\n",
    "]\n",
    "\n",
    "print(f\"‚úÖ Created {len(documents)} documents for hybrid search\")\n",
    "for doc in documents:\n",
    "    print(f\"  - {doc.metadata['topic']} ({doc.metadata['doc_type']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Simulating Hybrid Search (Conceptual)\n",
    "\n",
    "**Note**: True hybrid search requires a vector database with BM25 support (like Qdrant). For this demo, we'll show the concept and implementation pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1920efb526a4bcdac1c81d9eb0e10ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da520d03b4db4527aaf40717a255e231",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Vector index created\n"
     ]
    }
   ],
   "source": [
    "# Create standard vector index\n",
    "index = VectorStoreIndex.from_documents(documents, show_progress=True)\n",
    "print(\"‚úÖ Vector index created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Qdrant Hybrid Search (Code Example)\n",
    "\n",
    "**With Qdrant installed:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2mUsing Python 3.12.9 environment at: /Users/sourangshupal/Downloads/llama-index-tutorials/.venv\u001b[0m\n",
      "\u001b[2K\u001b[2mResolved \u001b[1m27 packages\u001b[0m \u001b[2min 1.51s\u001b[0m\u001b[0m                                        \u001b[0m\n",
      "\u001b[2K\u001b[2mPrepared \u001b[1m1 package\u001b[0m \u001b[2min 372ms\u001b[0m\u001b[0m                                              \n",
      "\u001b[2mUninstalled \u001b[1m1 package\u001b[0m \u001b[2min 16ms\u001b[0m\u001b[0m\n",
      "\u001b[2K\u001b[2mInstalled \u001b[1m4 packages\u001b[0m \u001b[2min 21ms\u001b[0m\u001b[0m                                \u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mfastembed\u001b[0m\u001b[2m==0.7.4\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mloguru\u001b[0m\u001b[2m==0.7.3\u001b[0m\n",
      " \u001b[31m-\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==12.0.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpillow\u001b[0m\u001b[2m==11.3.0\u001b[0m\n",
      " \u001b[32m+\u001b[39m \u001b[1mpy-rust-stemmers\u001b[0m\u001b[2m==0.1.5\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!uv pip install fastembed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7176592415d94dada8c7fefedda5f7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "141e11d9e8cc4a4c86e1c78ac415aeba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.onnx:   0%|          | 0.00/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a7506ab38445dab934a9d7f676dcf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dde56fac750a4c9194d0394888bf9686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd45d943fc9449c7a391a9c177371111",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5add08e541b046e3a5fe25b9983c0c96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/755 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d5277944d6e4222885f0ab00e96dafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "439a58c256b44fe88cbc2c2113f58969",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Qdrant hybrid search enabled\n",
      "   Mode: hybrid (semantic + BM25)\n",
      "   Alpha: 0.5 (equal weighting)\n"
     ]
    }
   ],
   "source": [
    "if QDRANT_AVAILABLE:\n",
    "    # Initialize Qdrant client\n",
    "    qdrant_client = QdrantClient(location=\":memory:\")\n",
    "    \n",
    "    # Create Qdrant vector store with hybrid search enabled\n",
    "    qdrant_vector_store = QdrantVectorStore(\n",
    "        client=qdrant_client,\n",
    "        collection_name=\"hybrid_search_demo\",\n",
    "        enable_hybrid=True,  # Enable BM25 + semantic search\n",
    "        batch_size=20,\n",
    "    )\n",
    "    \n",
    "    storage_context = StorageContext.from_defaults(vector_store=qdrant_vector_store)\n",
    "    \n",
    "    # Create index\n",
    "    hybrid_index = VectorStoreIndex.from_documents(\n",
    "        documents,\n",
    "        storage_context=storage_context,\n",
    "        show_progress=True,\n",
    "    )\n",
    "    \n",
    "    # Query with hybrid search\n",
    "    hybrid_query_engine = hybrid_index.as_query_engine(\n",
    "        similarity_top_k=3,\n",
    "        vector_store_query_mode=\"hybrid\",  # Use hybrid search\n",
    "        alpha=0.5,  # 50% semantic, 50% keyword\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Qdrant hybrid search enabled\")\n",
    "    print(\"   Mode: hybrid (semantic + BM25)\")\n",
    "    print(\"   Alpha: 0.5 (equal weighting)\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Qdrant not available - skipping hybrid search demo\")\n",
    "    hybrid_query_engine = index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Hybrid Search Benefits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hybrid Search Test Queries:\n",
      "\n",
      "Query: What is BM25?\n",
      "Response: BM25 is a probabilistic ranking function utilized for information retrieval. It enhances the traditional TF-IDF method by incorporating term frequency saturation and document length normalization. The...\n",
      "Top source: bm25\n",
      "--------------------------------------------------------------------------------\n",
      "Query: How do you balance semantic and keyword search?\n",
      "Response: To balance semantic and keyword search, you can adjust the alpha parameter in hybrid search. This parameter determines the weight given to each search method. An alpha value of 0 represents a pure key...\n",
      "Top source: hybrid_search\n",
      "--------------------------------------------------------------------------------\n",
      "Query: vector database for production\n",
      "Response: A suitable option for a production vector database is Qdrant. It is designed to handle both dense and sparse vectors and supports hybrid search, which combines semantic similarity with traditional key...\n",
      "Top source: vector_databases\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test queries that benefit from hybrid search\n",
    "test_queries = [\n",
    "    \"What is BM25?\",  # Exact term match important\n",
    "    \"How do you balance semantic and keyword search?\",  # Conceptual + keyword\n",
    "    \"vector database for production\",  # Keywords important\n",
    "]\n",
    "\n",
    "print(\"Hybrid Search Test Queries:\\n\")\n",
    "for query in test_queries:\n",
    "    response = hybrid_query_engine.query(query)\n",
    "    print(f\"Query: {query}\")\n",
    "    print(f\"Response: {str(response)[:200]}...\")\n",
    "    print(f\"Top source: {response.source_nodes[0].metadata.get('topic')}\")\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ ML Engineering Note: Alpha Parameter Tuning\n",
    "\n",
    "**Alpha controls dense/sparse balance:**\n",
    "\n",
    "```python\n",
    "final_score = alpha * semantic_score + (1 - alpha) * bm25_score\n",
    "```\n",
    "\n",
    "**Tuning Strategy:**\n",
    "\n",
    "1. **Create validation set**: 20-50 queries with known relevant docs\n",
    "2. **Test alphas**: [0.0, 0.1, 0.2, ..., 0.9, 1.0]\n",
    "3. **Measure metrics**: Precision@K, Recall@K, MRR\n",
    "4. **Select optimal**: Highest metric value\n",
    "\n",
    "**Common Patterns:**\n",
    "- **Technical docs**: Œ± ‚âà 0.3-0.4 (favor keywords for code, APIs)\n",
    "- **General knowledge**: Œ± ‚âà 0.6-0.7 (favor semantic)\n",
    "- **Product search**: Œ± ‚âà 0.4-0.5 (balanced)\n",
    "- **Scientific papers**: Œ± ‚âà 0.5-0.6 (balanced, slight semantic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Reranking Models\n",
    "\n",
    "### Why Rerank?\n",
    "\n",
    "**Two-stage retrieval:**\n",
    "1. **Stage 1 (Retrieval)**: Fast, recall-focused (get 50-100 candidates)\n",
    "2. **Stage 2 (Reranking)**: Slow, precision-focused (rerank top 10-20)\n",
    "\n",
    "**Cost-Performance Trade-off:**\n",
    "- Initial retrieval: Cheap (vector similarity or BM25)\n",
    "- Reranking: Expensive (cross-encoder models)\n",
    "- Result: Best of both worlds\n",
    "\n",
    "### 5.1 SentenceTransformer Cross-Encoder Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading cross-encoder model (first run may take a moment)...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a4cb76f0144a9da5e4827247b65abd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0126b3a1bf9e4ecf99b173a81eded471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/62.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feb4dde91ea248028792905277ff234e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a479f6435c5d4bc5be28056f06438fd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99ed8b26271e4ee8b71194d8bbed51c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bb0cc0a00af468bbf1d8d26796a3ead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/132 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc5bbde8fb9946d289b4893dee171556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Reranking query engine created\n",
      "   Initial retrieval: top 10\n",
      "   After reranking: top 3\n",
      "   Model: cross-encoder/ms-marco-MiniLM-L-2-v2\n"
     ]
    }
   ],
   "source": [
    "# Create cross-encoder reranker\n",
    "print(\"Loading cross-encoder model (first run may take a moment)...\")\n",
    "\n",
    "reranker = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\",  # Fast, lightweight\n",
    "    top_n=3,  # Return top 3 after reranking\n",
    ")\n",
    "\n",
    "# Create query engine with reranking\n",
    "reranked_query_engine = index.as_query_engine(\n",
    "    similarity_top_k=10,  # Retrieve 10 candidates\n",
    "    node_postprocessors=[reranker],  # Rerank to top 3\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ Reranking query engine created\")\n",
    "print(\"   Initial retrieval: top 10\")\n",
    "print(\"   After reranking: top 3\")\n",
    "print(\"   Model: cross-encoder/ms-marco-MiniLM-L-2-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does hybrid search combine different retrieval methods?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Without Reranking (similarity only):\n",
      "Top 3 sources:\n",
      "  1. hybrid_search (score: 0.7169)\n",
      "  2. reranking (score: 0.4180)\n",
      "  3. alpha_tuning (score: 0.4074)\n",
      "\n",
      "With Cross-Encoder Reranking:\n",
      "Top 3 sources (after reranking):\n",
      "  1. hybrid_search (score: 2.9632)\n",
      "  2. alpha_tuning (score: -3.7781)\n",
      "  3. qdrant (score: -4.4877)\n"
     ]
    }
   ],
   "source": [
    "# Compare with and without reranking\n",
    "test_query = \"How does hybrid search combine different retrieval methods?\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Without reranking\n",
    "print(\"\\nWithout Reranking (similarity only):\")\n",
    "no_rerank_engine = index.as_query_engine(similarity_top_k=3)\n",
    "no_rerank_response = no_rerank_engine.query(test_query)\n",
    "print(\"Top 3 sources:\")\n",
    "for i, node in enumerate(no_rerank_response.source_nodes, 1):\n",
    "    print(f\"  {i}. {node.metadata.get('topic')} (score: {node.score:.4f})\")\n",
    "\n",
    "# With reranking\n",
    "print(\"\\nWith Cross-Encoder Reranking:\")\n",
    "reranked_response = reranked_query_engine.query(test_query)\n",
    "print(\"Top 3 sources (after reranking):\")\n",
    "for i, node in enumerate(reranked_response.source_nodes, 1):\n",
    "    print(f\"  {i}. {node.metadata.get('topic')} (score: {node.score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Cohere Rerank (API-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COHERE_AVAILABLE and os.getenv(\"COHERE_API_KEY\"):\n",
    "    # Create Cohere reranker\n",
    "    cohere_reranker = CohereRerank(\n",
    "        api_key=os.getenv(\"COHERE_API_KEY\"),\n",
    "        top_n=3,\n",
    "        model=\"rerank-english-v3.0\",  # Latest Cohere rerank model\n",
    "    )\n",
    "    \n",
    "    # Create query engine with Cohere reranking\n",
    "    cohere_query_engine = index.as_query_engine(\n",
    "        similarity_top_k=10,\n",
    "        node_postprocessors=[cohere_reranker],\n",
    "    )\n",
    "    \n",
    "    print(\"‚úÖ Cohere reranking enabled\")\n",
    "    print(\"   Model: rerank-english-v3.0\")\n",
    "    \n",
    "    # Test Cohere reranking\n",
    "    cohere_response = cohere_query_engine.query(test_query)\n",
    "    print(\"\\nCohere Reranked Results:\")\n",
    "    for i, node in enumerate(cohere_response.source_nodes, 1):\n",
    "        print(f\"  {i}. {node.metadata.get('topic')} (score: {node.score:.4f})\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Cohere reranking not available (missing API key or package)\")\n",
    "    print(\"   Get free API key at: https://dashboard.cohere.com/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking Model Comparison\n",
    "\n",
    "| Model | Quality | Speed | Cost | Hosting |\n",
    "|-------|---------|-------|------|--------|\n",
    "| **Cross-Encoder (local)** | Good | Fast (GPU) | Free | Self-hosted |\n",
    "| **Cohere Rerank** | Excellent | Fast | $1/1000 searches | API |\n",
    "| **Custom fine-tuned** | Variable | Variable | Training cost | Self-hosted |\n",
    "\n",
    "**Recommendation:**\n",
    "- **Development**: Cross-encoder (free, fast iteration)\n",
    "- **Production (budget)**: Cross-encoder with GPU\n",
    "- **Production (quality)**: Cohere Rerank"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
