{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 4: Advanced Retrieval\n",
    "\n",
    "**Difficulty:** Intermediate-Advanced | **Estimated Time:** 120-150 minutes\n",
    "\n",
    "## Learning Objectives\n",
    "\n",
    "By the end of this notebook, you will be able to:\n",
    "\n",
    "1. âœ… Implement RecursiveRetriever for hierarchical document retrieval\n",
    "2. âœ… Use QueryFusionRetriever to combine multiple retrieval strategies\n",
    "3. âœ… Build custom retrievers with specialized ranking logic\n",
    "4. âœ… Apply query transformation techniques (HyDE, rewriting, multi-query)\n",
    "5. âœ… Implement complex metadata filtering (AND/OR/NOT logic)\n",
    "6. âœ… Evaluate retrieval quality with metrics\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- Completed Notebooks 1, 2, and 3\n",
    "- Understanding of embeddings and vector similarity\n",
    "- Familiarity with basic retrievers\n",
    "\n",
    "## Curriculum Coverage\n",
    "\n",
    "- **Section 3.5.3-3.5.5:** RecursiveRetriever, QueryFusionRetriever, Custom Retrievers\n",
    "- **Section 3.6:** Query Optimization\n",
    "- **Section 4.3:** Query Engines with Filters\n",
    "- **Section 4.4:** Advanced Retrieval Strategies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Setup & Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Imports successful!\n"
     ]
    }
   ],
   "source": [
    "# Core LlamaIndex\n",
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    Settings,\n",
    "    Document,\n",
    "    SummaryIndex,\n",
    ")\n",
    "from llama_index.core.schema import TextNode, IndexNode, NodeWithScore\n",
    "from llama_index.core.retrievers import (\n",
    "    VectorIndexRetriever,\n",
    "    RecursiveRetriever,\n",
    "    QueryFusionRetriever,\n",
    "    BaseRetriever,\n",
    ")\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "\n",
    "# Query transformations\n",
    "from llama_index.core.indices.query.query_transform import HyDEQueryTransform\n",
    "from llama_index.core.query_engine import TransformQueryEngine\n",
    "\n",
    "# Metadata filtering\n",
    "from llama_index.core.vector_stores import (\n",
    "    MetadataFilters,\n",
    "    MetadataFilter,\n",
    "    FilterOperator,\n",
    "    FilterCondition,\n",
    ")\n",
    "\n",
    "# LLM and Embeddings\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "\n",
    "# Utilities\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from typing import List, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"âœ… Imports successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Settings configured\n"
     ]
    }
   ],
   "source": [
    "# Configure Settings\n",
    "load_dotenv()\n",
    "\n",
    "Settings.llm = OpenAI(model=\"gpt-4o-mini\", temperature=0.1)\n",
    "Settings.embed_model = OpenAIEmbedding(\n",
    "    model=\"text-embedding-3-small\",\n",
    "    dimensions=1536\n",
    ")\n",
    "\n",
    "print(\"âœ… Settings configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Prepare Hierarchical Research Paper Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created 3 research papers with hierarchical structure\n",
      "  - Attention Is All You Need (2017) - 3 sections\n",
      "  - BERT: Pre-training of Deep Bidirectional Transformers (2019) - 3 sections\n",
      "  - Retrieval-Augmented Generation (RAG) (2020) - 3 sections\n"
     ]
    }
   ],
   "source": [
    "# Create research papers with hierarchical structure\n",
    "papers_data = [\n",
    "    {\n",
    "        \"title\": \"Attention Is All You Need\",\n",
    "        \"authors\": \"Vaswani et al.\",\n",
    "        \"year\": 2017,\n",
    "        \"citations\": 85000,\n",
    "        \"category\": \"transformers\",\n",
    "        \"abstract\": \"\"\"We propose a new simple network architecture, the Transformer, based solely \n",
    "        on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments show \n",
    "        that the Transformer achieves state-of-the-art results in machine translation while being more \n",
    "        parallelizable and requiring significantly less time to train.\"\"\",\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"name\": \"Introduction\",\n",
    "                \"content\": \"\"\"Recurrent neural networks have been the dominant approach for sequence modeling. \n",
    "                However, they are inherently sequential and cannot be parallelized. The Transformer is the \n",
    "                first transduction model relying entirely on self-attention to compute representations.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Model Architecture\",\n",
    "                \"content\": \"\"\"The Transformer follows an encoder-decoder structure. The encoder maps an input \n",
    "                sequence to a sequence of continuous representations. The decoder generates an output sequence \n",
    "                one element at a time. Both use stacked self-attention and point-wise fully connected layers.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Self-Attention\",\n",
    "                \"content\": \"\"\"Self-attention allows the model to attend to different positions of the input \n",
    "                sequence when encoding each position. We use scaled dot-product attention and multi-head \n",
    "                attention mechanisms. This enables modeling of dependencies regardless of distance.\"\"\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"BERT: Pre-training of Deep Bidirectional Transformers\",\n",
    "        \"authors\": \"Devlin et al.\",\n",
    "        \"year\": 2019,\n",
    "        \"citations\": 65000,\n",
    "        \"category\": \"language_models\",\n",
    "        \"abstract\": \"\"\"BERT is designed to pre-train deep bidirectional representations from unlabeled text \n",
    "        by jointly conditioning on both left and right context. Pre-trained BERT can be fine-tuned with \n",
    "        just one additional output layer for a wide range of tasks.\"\"\",\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"name\": \"Introduction\",\n",
    "                \"content\": \"\"\"Language model pre-training has been shown to be effective for many NLP tasks. \n",
    "                BERT alleviates the unidirectionality constraint by using a masked language model (MLM) \n",
    "                pre-training objective, which randomly masks tokens and predicts them.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Pre-training Tasks\",\n",
    "                \"content\": \"\"\"BERT uses two pre-training tasks: Masked Language Model (MLM) and Next Sentence \n",
    "                Prediction (NSP). MLM masks 15% of tokens randomly and predicts them. NSP predicts whether \n",
    "                two sentences follow each other in the original text.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Fine-tuning\",\n",
    "                \"content\": \"\"\"For sequence-level tasks, we take the final hidden state of the [CLS] token. \n",
    "                For token-level tasks like NER, we take the final hidden state of each token. Fine-tuning \n",
    "                is straightforward and requires minimal task-specific modifications.\"\"\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Retrieval-Augmented Generation (RAG)\",\n",
    "        \"authors\": \"Lewis et al.\",\n",
    "        \"year\": 2020,\n",
    "        \"citations\": 3500,\n",
    "        \"category\": \"rag\",\n",
    "        \"abstract\": \"\"\"We explore RAG models which combine parametric and non-parametric memory for \n",
    "        language generation. RAG models use a dense vector index of Wikipedia as non-parametric memory \n",
    "        and a pre-trained seq2seq transformer as parametric memory.\"\"\",\n",
    "        \"sections\": [\n",
    "            {\n",
    "                \"name\": \"Introduction\",\n",
    "                \"content\": \"\"\"Pre-trained language models store knowledge in parameters but struggle with \n",
    "                knowledge-intensive tasks. RAG provides access to external knowledge through retrieval, \n",
    "                allowing more interpretable and modular systems.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"RAG Architecture\",\n",
    "                \"content\": \"\"\"RAG has two components: a retriever based on DPR (Dense Passage Retrieval) and \n",
    "                a generator based on BART. The retriever finds relevant documents, which are concatenated \n",
    "                with the input and fed to the generator.\"\"\"\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Training\",\n",
    "                \"content\": \"\"\"We train RAG end-to-end by marginalizing over retrieved documents. The retriever \n",
    "                and generator are jointly optimized. This allows the model to learn which documents are most \n",
    "                useful for generation.\"\"\"\n",
    "            },\n",
    "        ]\n",
    "    },\n",
    "]\n",
    "\n",
    "print(f\"âœ… Created {len(papers_data)} research papers with hierarchical structure\")\n",
    "for paper in papers_data:\n",
    "    print(f\"  - {paper['title']} ({paper['year']}) - {len(paper['sections'])} sections\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. RecursiveRetriever: Hierarchical Document Structure\n",
    "\n",
    "### Why RecursiveRetriever?\n",
    "\n",
    "For documents with **hierarchical structure** (papers with sections, books with chapters):\n",
    "- **Top-level nodes**: Summaries or abstracts\n",
    "- **Detail nodes**: Full sections or chapters\n",
    "- **RecursiveRetriever**: Retrieves top-level, then drills down to details\n",
    "\n",
    "### Building Hierarchical Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created hierarchical structure:\n",
      "   Top-level summary nodes: 3\n",
      "   Detail section nodes: 9\n"
     ]
    }
   ],
   "source": [
    "# Build hierarchical structure\n",
    "all_nodes = []\n",
    "index_nodes = []  # Top-level summary nodes\n",
    "retriever_dict = {}\n",
    "\n",
    "for paper in papers_data:\n",
    "    # Create nodes for each section\n",
    "    section_nodes = []\n",
    "    for section in paper[\"sections\"]:\n",
    "        node = TextNode(\n",
    "            text=section[\"content\"],\n",
    "            metadata={\n",
    "                \"title\": paper[\"title\"],\n",
    "                \"section\": section[\"name\"],\n",
    "                \"year\": paper[\"year\"],\n",
    "                \"category\": paper[\"category\"],\n",
    "                \"citations\": paper[\"citations\"],\n",
    "            }\n",
    "        )\n",
    "        section_nodes.append(node)\n",
    "        all_nodes.append(node)\n",
    "    \n",
    "    # Create vector index for this paper's sections\n",
    "    paper_index = VectorStoreIndex(section_nodes)\n",
    "\n",
    "    # Store retriever in dictionary (NOT in index_node.obj)\n",
    "    retriever_dict[paper[\"title\"]] = paper_index.as_retriever(similarity_top_k=2)\n",
    "    \n",
    "    # Create summary node (IndexNode) pointing to the paper's index\n",
    "    index_node = IndexNode(\n",
    "        text=paper[\"abstract\"],\n",
    "        index_id=paper[\"title\"],\n",
    "        metadata={\n",
    "            \"title\": paper[\"title\"],\n",
    "            \"authors\": paper[\"authors\"],\n",
    "            \"year\": paper[\"year\"],\n",
    "            \"category\": paper[\"category\"],\n",
    "            \"citations\": paper[\"citations\"],\n",
    "            \"type\": \"summary\",\n",
    "        },\n",
    "    )\n",
    "    #index_node.obj = paper_index.as_retriever(similarity_top_k=2)\n",
    "    index_nodes.append(index_node)\n",
    "\n",
    "print(f\"âœ… Created hierarchical structure:\")\n",
    "print(f\"   Top-level summary nodes: {len(index_nodes)}\")\n",
    "print(f\"   Detail section nodes: {len(all_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['Attention Is All You Need', 'BERT: Pre-training of Deep Bidirectional Transformers', 'Retrieval-Augmented Generation (RAG)'])\n"
     ]
    }
   ],
   "source": [
    "print(retriever_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… RecursiveRetriever created\n"
     ]
    }
   ],
   "source": [
    "# Create top-level index of summaries\n",
    "top_level_index = VectorStoreIndex(index_nodes)\n",
    "\n",
    "for index_node in index_nodes:\n",
    "    paper_title = index_node.index_id\n",
    "    index_node.obj = retriever_dict[paper_title]\n",
    "\n",
    "\n",
    "# Add the top-level retriever to the dictionary\n",
    "retriever_dict[\"vector\"] = top_level_index.as_retriever(similarity_top_k=2)\n",
    "\n",
    "# Create recursive retriever\n",
    "recursive_retriever = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict=retriever_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "print(\"âœ… RecursiveRetriever created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: How does the Transformer architecture handle sequential data?\n",
      "\n",
      "RecursiveRetriever will:\n",
      "  1. Search top-level summaries (abstracts)\n",
      "  2. Retrieve detailed sections from matching papers\n",
      "\n",
      "\u001b[1;3;34mRetrieving with query id None: How does the Transformer architecture handle sequential data?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: Attention Is All You Need\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id Attention Is All You Need: How does the Transformer architecture handle sequential data?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: The Transformer follows an encoder-decoder structure. The encoder maps an input \n",
      "                sequence to a sequence of continuous representations. The decoder generates an output sequence \n",
      "                one element at a time. Both use stacked self-attention and point-wise fully connected layers.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Recurrent neural networks have been the dominant approach for sequence modeling. \n",
      "                However, they are inherently sequential and cannot be parallelized. The Transformer is the \n",
      "                first transduction model relying entirely on self-attention to compute representations.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieved node with id, entering: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "\u001b[0m\u001b[1;3;34mRetrieving with query id BERT: Pre-training of Deep Bidirectional Transformers: How does the Transformer architecture handle sequential data?\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: BERT uses two pre-training tasks: Masked Language Model (MLM) and Next Sentence \n",
      "                Prediction (NSP). MLM masks 15% of tokens randomly and predicts them. NSP predicts whether \n",
      "                two sentences follow each other in the original text.\n",
      "\u001b[0m\u001b[1;3;38;5;200mRetrieving text node: Language model pre-training has been shown to be effective for many NLP tasks. \n",
      "                BERT alleviates the unidirectionality constraint by using a masked language model (MLM) \n",
      "                pre-training objective, which randomly masks tokens and predicts them.\n",
      "\u001b[0m\n",
      "Retrieved 4 nodes:\n",
      "\n",
      "Node 1:\n",
      "  Title: Attention Is All You Need\n",
      "  Section: Model Architecture\n",
      "  Score: 0.5831\n",
      "  Text (first 150 chars): The Transformer follows an encoder-decoder structure. The encoder maps an input \n",
      "                sequence to a sequence of continuous representations....\n",
      "\n",
      "Node 2:\n",
      "  Title: Attention Is All You Need\n",
      "  Section: Introduction\n",
      "  Score: 0.5597\n",
      "  Text (first 150 chars): Recurrent neural networks have been the dominant approach for sequence modeling. \n",
      "                However, they are inherently sequential and cannot b...\n",
      "\n",
      "Node 3:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Section: Pre-training Tasks\n",
      "  Score: 0.3027\n",
      "  Text (first 150 chars): BERT uses two pre-training tasks: Masked Language Model (MLM) and Next Sentence \n",
      "                Prediction (NSP). MLM masks 15% of tokens randomly an...\n",
      "\n",
      "Node 4:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Section: Introduction\n",
      "  Score: 0.2886\n",
      "  Text (first 150 chars): Language model pre-training has been shown to be effective for many NLP tasks. \n",
      "                BERT alleviates the unidirectionality constraint by us...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query with recursive retriever\n",
    "query = \"How does the Transformer architecture handle sequential data?\"\n",
    "\n",
    "print(f\"Query: {query}\\n\")\n",
    "print(\"RecursiveRetriever will:\")\n",
    "print(\"  1. Search top-level summaries (abstracts)\")\n",
    "print(\"  2. Retrieve detailed sections from matching papers\\n\")\n",
    "\n",
    "nodes = recursive_retriever.retrieve(query)\n",
    "\n",
    "print(f\"\\nRetrieved {len(nodes)} nodes:\\n\")\n",
    "for i, node in enumerate(nodes, 1):\n",
    "    print(f\"Node {i}:\")\n",
    "    print(f\"  Title: {node.metadata.get('title')}\")\n",
    "    print(f\"  Section: {node.metadata.get('section', 'N/A')}\")\n",
    "    print(f\"  Score: {node.score:.4f}\")\n",
    "    print(f\"  Text (first 150 chars): {node.text[:150]}...\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RecursiveRetriever Benefits\n",
    "\n",
    "**Advantages:**\n",
    "- âœ… **Efficient for large documents**: First filter by summary, then get details\n",
    "- âœ… **Better precision**: Two-stage retrieval reduces noise\n",
    "- âœ… **Flexible structure**: Supports arbitrary depth hierarchies\n",
    "\n",
    "**Use cases:**\n",
    "- Research papers (abstract â†’ sections)\n",
    "- Books (chapters â†’ subsections)\n",
    "- Documentation (overview â†’ detailed guides)\n",
    "- Legal documents (summary â†’ clauses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. QueryFusionRetriever: Combining Multiple Strategies\n",
    "\n",
    "### Why Query Fusion?\n",
    "\n",
    "Different retrievers excel at different tasks:\n",
    "- **Vector retriever**: Semantic similarity\n",
    "- **Keyword retriever**: Exact term matching\n",
    "- **Metadata retriever**: Structured filtering\n",
    "\n",
    "**QueryFusionRetriever** combines multiple retrievers using **Reciprocal Rank Fusion (RRF)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Created flat index with 12 documents\n"
     ]
    }
   ],
   "source": [
    "# Create a flat index for fusion experiments\n",
    "flat_documents = []\n",
    "for paper in papers_data:\n",
    "    # Add abstract\n",
    "    flat_documents.append(Document(\n",
    "        text=f\"{paper['title']}\\n\\nAbstract: {paper['abstract']}\",\n",
    "        metadata={\n",
    "            \"title\": paper[\"title\"],\n",
    "            \"year\": paper[\"year\"],\n",
    "            \"category\": paper[\"category\"],\n",
    "            \"citations\": paper[\"citations\"],\n",
    "            \"type\": \"abstract\"\n",
    "        }\n",
    "    ))\n",
    "    # Add sections\n",
    "    for section in paper[\"sections\"]:\n",
    "        flat_documents.append(Document(\n",
    "            text=f\"{paper['title']} - {section['name']}\\n\\n{section['content']}\",\n",
    "            metadata={\n",
    "                \"title\": paper[\"title\"],\n",
    "                \"section\": section[\"name\"],\n",
    "                \"year\": paper[\"year\"],\n",
    "                \"category\": paper[\"category\"],\n",
    "                \"type\": \"section\"\n",
    "            }\n",
    "        ))\n",
    "\n",
    "fusion_index = VectorStoreIndex.from_documents(flat_documents)\n",
    "print(f\"âœ… Created flat index with {len(flat_documents)} documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… QueryFusionRetriever created with 2 retrievers\n"
     ]
    }
   ],
   "source": [
    "# Create multiple retrievers with different strategies\n",
    "\n",
    "# Retriever 1: High similarity threshold (precision-focused)\n",
    "precision_retriever = VectorIndexRetriever(\n",
    "    index=fusion_index,\n",
    "    similarity_top_k=5,\n",
    ")\n",
    "\n",
    "# Retriever 2: Lower threshold, more results (recall-focused)\n",
    "recall_retriever = VectorIndexRetriever(\n",
    "    index=fusion_index,\n",
    "    similarity_top_k=8,\n",
    ")\n",
    "\n",
    "# Create QueryFusionRetriever\n",
    "fusion_retriever = QueryFusionRetriever(\n",
    "    retrievers=[precision_retriever, recall_retriever],\n",
    "    similarity_top_k=5,  # Final number of results\n",
    "    num_queries=1,  # Generate 1 query variant\n",
    "    mode=\"reciprocal_rerank\",  # Use Reciprocal Rank Fusion\n",
    "    use_async=False,\n",
    ")\n",
    "\n",
    "print(\"âœ… QueryFusionRetriever created with 2 retrievers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the key innovations in BERT?\n",
      "\n",
      "Retrieved 5 fused results:\n",
      "\n",
      "Node 1:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Type: abstract\n",
      "  Section: N/A\n",
      "  Score: 0.0333\n",
      "\n",
      "Node 2:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Type: section\n",
      "  Section: Introduction\n",
      "  Score: 0.0328\n",
      "\n",
      "Node 3:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Type: section\n",
      "  Section: Fine-tuning\n",
      "  Score: 0.0323\n",
      "\n",
      "Node 4:\n",
      "  Title: BERT: Pre-training of Deep Bidirectional Transformers\n",
      "  Type: section\n",
      "  Section: Pre-training Tasks\n",
      "  Score: 0.0317\n",
      "\n",
      "Node 5:\n",
      "  Title: Attention Is All You Need\n",
      "  Type: abstract\n",
      "  Section: N/A\n",
      "  Score: 0.0312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query with fusion retriever\n",
    "fusion_query = \"What are the key innovations in BERT?\"\n",
    "\n",
    "print(f\"Query: {fusion_query}\\n\")\n",
    "fusion_nodes = fusion_retriever.retrieve(fusion_query)\n",
    "\n",
    "print(f\"Retrieved {len(fusion_nodes)} fused results:\\n\")\n",
    "for i, node in enumerate(fusion_nodes, 1):\n",
    "    print(f\"Node {i}:\")\n",
    "    print(f\"  Title: {node.metadata.get('title')}\")\n",
    "    print(f\"  Type: {node.metadata.get('type')}\")\n",
    "    print(f\"  Section: {node.metadata.get('section', 'N/A')}\")\n",
    "    print(f\"  Score: {node.score:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ ML Engineering Note: Reciprocal Rank Fusion (RRF)\n",
    "\n",
    "**How RRF Works:**\n",
    "\n",
    "For each document, RRF score = Î£(1 / (k + rank_i))\n",
    "- `k`: Constant (typically 60)\n",
    "- `rank_i`: Document's rank in retriever i\n",
    "\n",
    "**Example:**\n",
    "- Doc A: Rank 1 in Retriever 1, Rank 3 in Retriever 2\n",
    "- RRF score = 1/(60+1) + 1/(60+3) = 0.0164 + 0.0159 = 0.0323\n",
    "\n",
    "**Benefits:**\n",
    "- âœ… No normalization needed (rank-based, not score-based)\n",
    "- âœ… Robust to different scoring scales\n",
    "- âœ… Favors documents that rank well in multiple retrievers\n",
    "- âœ… Simple and effective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Custom Retriever Implementation\n",
    "\n",
    "### Building a Citation-Aware Retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… CitationBoostRetriever class defined\n"
     ]
    }
   ],
   "source": [
    "from llama_index.core.retrievers import BaseRetriever\n",
    "from llama_index.core.schema import QueryBundle\n",
    "\n",
    "class CitationBoostRetriever(BaseRetriever):\n",
    "    \"\"\"Custom retriever that boosts highly-cited papers.\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        base_retriever: BaseRetriever,\n",
    "        citation_weight: float = 0.3,\n",
    "    ):\n",
    "        \"\"\"Initialize with base retriever and citation weight.\n",
    "        \n",
    "        Args:\n",
    "            base_retriever: Underlying vector retriever\n",
    "            citation_weight: How much to boost based on citations (0-1)\n",
    "        \"\"\"\n",
    "        self._base_retriever = base_retriever\n",
    "        self._citation_weight = citation_weight\n",
    "        super().__init__()\n",
    "    \n",
    "    def _retrieve(self, query_bundle: QueryBundle) -> List[NodeWithScore]:\n",
    "        \"\"\"Retrieve nodes and re-rank by citations.\"\"\"\n",
    "        # Get base results\n",
    "        nodes = self._base_retriever.retrieve(query_bundle)\n",
    "        \n",
    "        # Re-rank with citation boost\n",
    "        max_citations = max(\n",
    "            node.metadata.get(\"citations\", 0) for node in nodes\n",
    "        ) or 1\n",
    "        \n",
    "        for node in nodes:\n",
    "            citations = node.metadata.get(\"citations\", 0)\n",
    "            citation_score = citations / max_citations\n",
    "            \n",
    "            # Combine similarity score with citation boost\n",
    "            original_score = node.score or 0\n",
    "            node.score = (\n",
    "                (1 - self._citation_weight) * original_score +\n",
    "                self._citation_weight * citation_score\n",
    "            )\n",
    "        \n",
    "        # Re-sort by new scores\n",
    "        nodes.sort(key=lambda x: x.score, reverse=True)\n",
    "        \n",
    "        return nodes\n",
    "\n",
    "print(\"âœ… CitationBoostRetriever class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: machine learning models\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Base Retriever (similarity only):\n",
      "  1. Retrieval-Augmented Generation (RAG) - Score: 0.3737, Citations: 0\n",
      "  2. BERT: Pre-training of Deep Bidirectional Transformers - Score: 0.3628, Citations: 0\n",
      "  3. Attention Is All You Need - Score: 0.3554, Citations: 0\n",
      "\n",
      "Citation-Boosted Retriever:\n",
      "  1. Retrieval-Augmented Generation (RAG) - Score: 0.2616, Citations: 0\n",
      "  2. BERT: Pre-training of Deep Bidirectional Transformers - Score: 0.2540, Citations: 0\n",
      "  3. Attention Is All You Need - Score: 0.2488, Citations: 0\n"
     ]
    }
   ],
   "source": [
    "# Create base retriever\n",
    "base_retriever = fusion_index.as_retriever(similarity_top_k=5)\n",
    "\n",
    "# Create citation-aware retriever\n",
    "citation_retriever = CitationBoostRetriever(\n",
    "    base_retriever=base_retriever,\n",
    "    citation_weight=0.3,  # 30% weight to citations\n",
    ")\n",
    "\n",
    "# Compare results\n",
    "test_query = \"machine learning models\"\n",
    "\n",
    "print(f\"Query: {test_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Base retriever results\n",
    "base_nodes = base_retriever.retrieve(test_query)\n",
    "print(\"\\nBase Retriever (similarity only):\")\n",
    "for i, node in enumerate(base_nodes[:3], 1):\n",
    "    print(f\"  {i}. {node.metadata.get('title')} - Score: {node.score:.4f}, Citations: {node.metadata.get('citations', 0)}\")\n",
    "\n",
    "# Citation-boosted results\n",
    "citation_nodes = citation_retriever.retrieve(test_query)\n",
    "print(\"\\nCitation-Boosted Retriever:\")\n",
    "for i, node in enumerate(citation_nodes[:3], 1):\n",
    "    print(f\"  {i}. {node.metadata.get('title')} - Score: {node.score:.4f}, Citations: {node.metadata.get('citations', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom Retriever Use Cases\n",
    "\n",
    "**When to build custom retrievers:**\n",
    "\n",
    "1. **Domain-specific ranking**: Boost based on recency, authority, citations\n",
    "2. **Business logic**: Apply pricing tiers, user permissions, content policies\n",
    "3. **Hybrid scoring**: Combine multiple signals (semantic + BM25 + custom)\n",
    "4. **A/B testing**: Experiment with ranking algorithms\n",
    "5. **Diversity**: Ensure results cover different aspects/sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Query Transformation: HyDE\n",
    "\n",
    "### What is HyDE?\n",
    "\n",
    "**HyDE (Hypothetical Document Embeddings)**:\n",
    "1. LLM generates a hypothetical answer to the query\n",
    "2. Embed the hypothetical answer (not the query)\n",
    "3. Retrieve documents similar to the hypothetical answer\n",
    "\n",
    "**Why?** Hypothetical answers are often more similar to real documents than queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… HyDE query engine created\n"
     ]
    }
   ],
   "source": [
    "# Create HyDE query transform\n",
    "hyde = HyDEQueryTransform(include_original=True)\n",
    "\n",
    "# Create base query engine\n",
    "base_query_engine = fusion_index.as_query_engine(similarity_top_k=3)\n",
    "\n",
    "# Wrap with HyDE transform\n",
    "hyde_query_engine = TransformQueryEngine(\n",
    "    base_query_engine,\n",
    "    query_transform=hyde,\n",
    ")\n",
    "\n",
    "print(\"âœ… HyDE query engine created\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What are the limitations of recurrent neural networks?\n",
      "\n",
      "================================================================================\n",
      "\n",
      "Standard Query Engine:\n",
      "Response: Recurrent neural networks are inherently sequential, which means they cannot be parallelized. This limitation affects their efficiency and speed in processing sequences.\n",
      "\n",
      "================================================================================\n",
      "\n",
      "HyDE Query Engine:\n",
      "(First generates hypothetical answer, then retrieves)\n",
      "Response: Recurrent neural networks are inherently sequential, which means they cannot be parallelized. This limitation affects their efficiency and scalability in sequence modeling tasks.\n"
     ]
    }
   ],
   "source": [
    "# Test HyDE vs standard retrieval\n",
    "hyde_query = \"What are the limitations of recurrent neural networks?\"\n",
    "\n",
    "print(f\"Query: {hyde_query}\\n\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Standard query\n",
    "print(\"\\nStandard Query Engine:\")\n",
    "standard_response = base_query_engine.query(hyde_query)\n",
    "print(f\"Response: {standard_response}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "\n",
    "# HyDE query\n",
    "print(\"\\nHyDE Query Engine:\")\n",
    "print(\"(First generates hypothetical answer, then retrieves)\")\n",
    "hyde_response = hyde_query_engine.query(hyde_query)\n",
    "print(f\"Response: {hyde_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ ML Engineering Note: HyDE Trade-offs\n",
    "\n",
    "**Pros:**\n",
    "- âœ… Better retrieval for complex queries\n",
    "- âœ… Handles vocabulary mismatch (query terms â‰  document terms)\n",
    "- âœ… Effective for knowledge-intensive questions\n",
    "\n",
    "**Cons:**\n",
    "- âŒ Extra LLM call (cost + latency)\n",
    "- âŒ Hallucinated hypothetical answer may mislead retrieval\n",
    "- âŒ Not always better than standard retrieval\n",
    "\n",
    "**Best for:**\n",
    "- Complex, open-ended questions\n",
    "- Domain-specific queries with jargon\n",
    "- When you have budget for extra LLM call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 7. Complex Metadata Filtering\n",
    "\n",
    "### AND/OR/NOT Logic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filter: year >= 2017 AND year <= 2019 AND category='transformers'\n",
      "Results: 4\n",
      "  - Attention Is All You Need (2017)\n",
      "  - Attention Is All You Need (2017)\n",
      "  - Attention Is All You Need (2017)\n",
      "  - Attention Is All You Need (2017)\n"
     ]
    }
   ],
   "source": [
    "# Create filters with complex logic\n",
    "\n",
    "# Example 1: Papers from 2017-2019 AND category='transformers'\n",
    "filters_and = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"year\", operator=FilterOperator.GTE, value=2017),\n",
    "        MetadataFilter(key=\"year\", operator=FilterOperator.LTE, value=2019),\n",
    "        MetadataFilter(key=\"category\", operator=FilterOperator.EQ, value=\"transformers\"),\n",
    "    ],\n",
    "    condition=FilterCondition.AND,\n",
    ")\n",
    "\n",
    "retriever_and = fusion_index.as_retriever(\n",
    "    similarity_top_k=5,\n",
    "    filters=filters_and,\n",
    ")\n",
    "\n",
    "results_and = retriever_and.retrieve(\"neural network architecture\")\n",
    "print(\"Filter: year >= 2017 AND year <= 2019 AND category='transformers'\")\n",
    "print(f\"Results: {len(results_and)}\")\n",
    "for node in results_and:\n",
    "    print(f\"  - {node.metadata.get('title')} ({node.metadata.get('year')})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Filter: citations > 10000 OR year >= 2020\n",
      "Results: 6\n",
      "  - Retrieval-Augmented Generation (RAG) (2020, None citations)\n",
      "  - BERT: Pre-training of Deep Bidirectional Transformers (2019, 65000 citations)\n",
      "  - Attention Is All You Need (2017, 85000 citations)\n"
     ]
    }
   ],
   "source": [
    "# Example 2: High citations (>10000) OR recent (year >= 2020)\n",
    "filters_or = MetadataFilters(\n",
    "    filters=[\n",
    "        MetadataFilter(key=\"citations\", operator=FilterOperator.GT, value=10000),\n",
    "        MetadataFilter(key=\"year\", operator=FilterOperator.GTE, value=2020),\n",
    "    ],\n",
    "    condition=FilterCondition.OR,\n",
    ")\n",
    "\n",
    "retriever_or = fusion_index.as_retriever(\n",
    "    similarity_top_k=10,\n",
    "    filters=filters_or,\n",
    ")\n",
    "\n",
    "results_or = retriever_or.retrieve(\"language models\")\n",
    "print(\"\\nFilter: citations > 10000 OR year >= 2020\")\n",
    "print(f\"Results: {len(results_or)}\")\n",
    "unique_titles = set()\n",
    "for node in results_or:\n",
    "    title = node.metadata.get('title')\n",
    "    if title not in unique_titles:\n",
    "        unique_titles.add(title)\n",
    "        print(f\"  - {title} ({node.metadata.get('year')}, {node.metadata.get('citations')} citations)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Filtering Patterns\n",
    "\n",
    "**Filter Operators:**\n",
    "- `EQ`: Equal\n",
    "- `NE`: Not equal\n",
    "- `GT`: Greater than\n",
    "- `GTE`: Greater than or equal\n",
    "- `LT`: Less than\n",
    "- `LTE`: Less than or equal\n",
    "- `IN`: In list\n",
    "- `NIN`: Not in list\n",
    "- `CONTAINS`: String contains\n",
    "\n",
    "**Filter Conditions:**\n",
    "- `AND`: All filters must match\n",
    "- `OR`: At least one filter must match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 8. Retrieval Evaluation\n",
    "\n",
    "### Measuring Retrieval Quality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieval Evaluation Metrics:\n",
      "  Precision@3: 33.33%\n",
      "  Recall@3: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Define evaluation queries with known relevant documents\n",
    "eval_queries = [\n",
    "    {\n",
    "        \"query\": \"How does self-attention work?\",\n",
    "        \"relevant_titles\": [\"Attention Is All You Need\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is masked language modeling?\",\n",
    "        \"relevant_titles\": [\"BERT: Pre-training of Deep Bidirectional Transformers\"],\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"How does retrieval augmented generation work?\",\n",
    "        \"relevant_titles\": [\"Retrieval-Augmented Generation (RAG)\"],\n",
    "    },\n",
    "]\n",
    "\n",
    "def evaluate_retrieval(retriever, queries, k=3):\n",
    "    \"\"\"Calculate precision@k and recall@k.\"\"\"\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    \n",
    "    for item in queries:\n",
    "        query = item[\"query\"]\n",
    "        relevant = set(item[\"relevant_titles\"])\n",
    "        \n",
    "        # Retrieve\n",
    "        nodes = retriever.retrieve(query)\n",
    "        retrieved_titles = [n.metadata.get(\"title\") for n in nodes[:k]]\n",
    "        retrieved = set(retrieved_titles)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        true_positives = len(relevant & retrieved)\n",
    "        precision = true_positives / k if k > 0 else 0\n",
    "        recall = true_positives / len(relevant) if relevant else 0\n",
    "        \n",
    "        precisions.append(precision)\n",
    "        recalls.append(recall)\n",
    "    \n",
    "    return {\n",
    "        \"precision@k\": sum(precisions) / len(precisions),\n",
    "        \"recall@k\": sum(recalls) / len(recalls),\n",
    "    }\n",
    "\n",
    "# Evaluate different retrievers\n",
    "base_retriever_eval = fusion_index.as_retriever(similarity_top_k=3)\n",
    "metrics = evaluate_retrieval(base_retriever_eval, eval_queries, k=3)\n",
    "\n",
    "print(\"Retrieval Evaluation Metrics:\")\n",
    "print(f\"  Precision@3: {metrics['precision@k']:.2%}\")\n",
    "print(f\"  Recall@3: {metrics['recall@k']:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸŽ¯ ML Engineering Note: Retrieval Metrics\n",
    "\n",
    "**Key Metrics:**\n",
    "\n",
    "1. **Precision@K**: Of K retrieved docs, how many are relevant?\n",
    "   - Formula: (relevant docs in top K) / K\n",
    "   - High precision = low false positives\n",
    "\n",
    "2. **Recall@K**: Of all relevant docs, how many are in top K?\n",
    "   - Formula: (relevant docs in top K) / (total relevant docs)\n",
    "   - High recall = low false negatives\n",
    "\n",
    "3. **MRR (Mean Reciprocal Rank)**: Where does first relevant doc appear?\n",
    "   - Formula: 1 / rank of first relevant doc\n",
    "   - Higher = relevant docs appear earlier\n",
    "\n",
    "4. **NDCG (Normalized Discounted Cumulative Gain)**: Weighted relevance\n",
    "   - Considers graded relevance and position\n",
    "   - Gold standard for ranking evaluation\n",
    "\n",
    "**Production Monitoring:**\n",
    "- Track precision@k and recall@k over time\n",
    "- Set alerts for metric degradation\n",
    "- A/B test retrieval strategies\n",
    "- Collect user feedback (clicks, dwell time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 9. Summary: What You Learned\n",
    "\n",
    "### âœ… Completed Learning Objectives\n",
    "\n",
    "1. **RecursiveRetriever**: Hierarchical retrieval for structured documents\n",
    "2. **QueryFusionRetriever**: Combined multiple retrievers with RRF\n",
    "3. **Custom Retrievers**: Built citation-aware re-ranking\n",
    "4. **Query Transformation**: Applied HyDE for better retrieval\n",
    "5. **Metadata Filtering**: Implemented complex AND/OR/NOT logic\n",
    "6. **Evaluation**: Measured retrieval quality with precision and recall\n",
    "\n",
    "### Key Concepts Mastered\n",
    "\n",
    "- **RecursiveRetriever**: Two-stage retrieval (summary â†’ details)\n",
    "- **QueryFusionRetriever**: Reciprocal Rank Fusion (RRF)\n",
    "- **Custom retrievers**: BaseRetriever subclass, custom scoring\n",
    "- **HyDE**: Hypothetical document embeddings\n",
    "- **Metadata filters**: FilterOperator, FilterCondition\n",
    "- **Evaluation metrics**: Precision@K, Recall@K, MRR\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "In **Notebook 5: Hybrid Search & Reranking**, you'll learn:\n",
    "- Dense vs sparse vectors (BM25)\n",
    "- Hybrid search with Qdrant\n",
    "- Alpha parameter tuning\n",
    "- Reranking models (Cohere, cross-encoders)\n",
    "- Custom query engines\n",
    "- Production patterns and optimization\n",
    "\n",
    "---\n",
    "\n",
    "## ðŸŽ¯ Practice Exercises\n",
    "\n",
    "1. **Hierarchical Documents**: Create a 3-level hierarchy (book â†’ chapter â†’ section) with RecursiveRetriever\n",
    "2. **Query Fusion**: Combine 3+ retrievers with different strategies. Measure improvement.\n",
    "3. **Custom Retriever**: Build a time-decay retriever that favors recent documents\n",
    "4. **HyDE Comparison**: Test HyDE on 10 queries. When does it help vs hurt?\n",
    "5. **Evaluation Suite**: Build comprehensive eval with MRR and NDCG\n",
    "\n",
    "---\n",
    "\n",
    "## Additional Resources\n",
    "\n",
    "- **Retrievers**: https://docs.llamaindex.ai/en/stable/module_guides/querying/retriever/\n",
    "- **Query Transformations**: https://docs.llamaindex.ai/en/stable/examples/query_transformations/\n",
    "- **Metadata Filtering**: https://docs.llamaindex.ai/en/stable/module_guides/querying/node_postprocessors/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
